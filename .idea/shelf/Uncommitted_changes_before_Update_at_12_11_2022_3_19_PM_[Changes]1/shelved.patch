Index: pages/KNN.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import streamlit as st\r\n\r\nfrom sklearn.datasets import make_blobs\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\nfrom sklearn.metrics import accuracy_score\r\nfrom sklearn import datasets\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nfrom skimage import exposure\r\nimport imutils\r\nimport cv2\r\nfrom tensorflow import keras \r\nimport joblib\r\n\r\nst.markdown(\"# KNN ❄️\")\r\nst.sidebar.markdown(\"# KNN ❄️\")\r\n\r\ndef get_fvalue(val):\r\n    feature_dict = {\"No\":1,\"Yes\":2}\r\n    for key,value in feature_dict.items():\r\n        if val == key:\r\n            return value\r\n\r\ndef get_value(val,my_dict):\r\n    for key,value in my_dict.items():\r\n        if val == key:\r\n            return value\r\n\r\napp_mode = st.sidebar.selectbox('Select Page',['Bai01','Bai02', 'Bai03', 'Bai3a', 'Bai04', 'Bai08']) \r\n\r\nif app_mode=='Bai01':\r\n    \r\n    st.title(\"Bài 1\") \r\n    np.random.seed(100)\r\n    N = 150\r\n\r\n    centers = [[2, 3], [5, 5], [1, 8]]\r\n    n_classes = len(centers)\r\n    data, labels = make_blobs(n_samples=N, \r\n                            centers=np.array(centers),\r\n                            random_state=1)\r\n\r\n    nhom_0 = []\r\n    nhom_1 = []\r\n    nhom_2 = []\r\n\r\n    for i in range(0, N):\r\n        if labels[i] == 0:\r\n            nhom_0.append([data[i,0], data[i,1]])\r\n        elif labels[i] == 1:\r\n            nhom_1.append([data[i,0], data[i,1]])\r\n        else:\r\n            nhom_2.append([data[i,0], data[i,1]])\r\n\r\n    nhom_0 = np.array(nhom_0)\r\n    nhom_1 = np.array(nhom_1)\r\n    nhom_2 = np.array(nhom_2)\r\n    \r\n    fig, ax = plt.subplots()\r\n    plt.plot(nhom_0[:,0], nhom_0[:,1], 'og', markersize = 2)\r\n    plt.plot(nhom_1[:,0], nhom_1[:,1], 'or', markersize = 2)\r\n    plt.plot(nhom_2[:,0], nhom_2[:,1], 'ob', markersize = 2)\r\n    plt.legend(['Nhom 0', 'Nhom 1', 'Nhom 2'])\r\n    res = train_test_split(data, labels, \r\n                       train_size=0.8,\r\n                       test_size=0.2,\r\n                       random_state=1)\r\n    \r\n    train_data, test_data, train_labels, test_labels = res \r\n    # default k = n_neighbors = 5\r\n    #         k = 3\r\n    knn = KNeighborsClassifier(n_neighbors = 3)\r\n    knn.fit(train_data, train_labels)\r\n    predicted = knn.predict(test_data)\r\n    sai_so = accuracy_score(test_labels, predicted)\r\n    st.write('sai so:', sai_so)\r\n\r\n    my_test = np.array([[2.5, 4.0]])\r\n    ket_qua = knn.predict(my_test)\r\n    st.write('Ket qua nhan dang la nhom:', ket_qua[0])\r\n    st.pyplot(fig)\r\nelif (app_mode == 'Bai02'):\r\n    st.title(\"Bài 02\") \r\n    # take the MNIST data and construct the training and testing split, using 75% of the\r\n    # data for training and 25% for testing\r\n    mnist = datasets.load_digits()\r\n    (trainData, testData, trainLabels, testLabels) = train_test_split(np.array(mnist.data),\r\n        mnist.target, test_size=0.25, random_state=42)\r\n\r\n    # now, let's take 10% of the training data and use that for validation\r\n    (trainData, valData, trainLabels, valLabels) = train_test_split(trainData, trainLabels,\r\n        test_size=0.1, random_state=84)\r\n\r\n    st.write(\"training data points: \", len(trainLabels))\r\n    st.write(\"validation data points: \", len(valLabels))\r\n    st.write(\"testing data points: \", len(testLabels))\r\n\r\n    model = KNeighborsClassifier()\r\n    model.fit(trainData, trainLabels)\r\n    # evaluate the model and update the accuracies list\r\n    score = model.score(valData, valLabels)\r\n    st.write(\"accuracy = %.2f%%\" % (score * 100))\r\n\r\n    # loop over a few random digits\r\n    for i in list(map(int, np.random.randint(0, high=len(testLabels), size=(5,)))):\r\n        # grab the image and classify it\r\n        image = testData[i]\r\n        prediction = model.predict(image.reshape(1, -1))[0]\r\n\r\n        # convert the image for a 64-dim array to an 8 x 8 image compatible with OpenCV,\r\n        # then resize it to 32 x 32 pixels so we can see it better\r\n        image = image.reshape((8, 8)).astype(\"uint8\")\r\n\r\n        image = exposure.rescale_intensity(image, out_range=(0, 255))\r\n        image = imutils.resize(image, width=32, inter=cv2.INTER_CUBIC)\r\n\r\n        # show the prediction\r\n        st.image(image, clamp=True)\r\n        st.write(\"I think that digit is: {}\".format(prediction))\r\nelif (app_mode =='Bai03'):\r\n\r\n    mnist = keras.datasets.mnist \r\n    (X_train, Y_train), (X_test, Y_test) = mnist.load_data() \r\n\r\n    # 784 = 28x28\r\n    RESHAPED = 784\r\n    X_train = X_train.reshape(60000, RESHAPED)\r\n    X_test = X_test.reshape(10000, RESHAPED) \r\n\r\n    # now, let's take 10% of the training data and use that for validation\r\n    (trainData, valData, trainLabels, valLabels) = train_test_split(X_train, Y_train,\r\n        test_size=0.1, random_state=84)\r\n\r\n    model = KNeighborsClassifier()\r\n    model.fit(trainData, trainLabels)\r\n\r\n    # save model, sau này ta sẽ load model để dùng \r\n    joblib.dump(model, \"knn_mnist.pkl\")\r\n\r\n    # Đánh giá trên tập validation\r\n    predicted = model.predict(valData)\r\n    do_chinh_xac = accuracy_score(valLabels, predicted)\r\n    st.write('Độ chính xác trên tập validation: %.0f%%' % (do_chinh_xac*100))\r\n\r\n    # Đánh giá trên tập test\r\n    predicted = model.predict(X_test)\r\n    do_chinh_xac = accuracy_score(Y_test, predicted)\r\n    st.write('Độ chính xác trên tập test: %.0f%%' % (do_chinh_xac*100))\r\n\r\nelif (app_mode =='Bai3a'):\r\n    st.title('Bài 3a')\r\n    \r\n    mnist = keras.datasets.mnist \r\n    (X_train, Y_train), (X_test, Y_test) = mnist.load_data() \r\n\r\n\r\n    index = np.random.randint(0, 9999, 100)\r\n    sample = np.zeros((100,28,28), np.uint8)\r\n    for i in range(0, 100):\r\n        sample[i] = X_test[index[i]]\r\n\r\n\r\n    # 784 = 28x28\r\n    RESHAPED = 784\r\n    sample = sample.reshape(100, RESHAPED) \r\n    knn = joblib.load(\"pages/KNN1/knn_mnist.pkl\")\r\n    predicted = knn.predict(sample)\r\n    k = 0\r\n    for x in range(0, 10):\r\n        for y in range(0, 10):\r\n            print('%2d' % (predicted[k]), end='')\r\n            k = k + 1\r\n        st.write()\r\n\r\n    digit = np.zeros((10*28,10*28), np.uint8)\r\n    k = 0\r\n    for x in range(0, 10):\r\n        for y in range(0, 10):\r\n            digit[x*28:(x+1)*28, y*28:(y+1)*28] = X_test[index[k]]\r\n            k = k + 1\r\n\r\n    st.image('pages/KNN1/digit.jpg')\r\nelif (app_mode == 'Bai04'):\r\n    \r\n    from PIL import ImageTk, Image\r\n    st.header(\"Bài 4\")\r\n    mnist = keras.datasets.mnist\r\n    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\r\n    index = None\r\n    knn = joblib.load('pages/KNN1/knn_mnist.pkl')\r\n    btn1 = st.button('Create Digit and Recognition')\r\n    if btn1:\r\n        col1,col2 = st.columns([15,20])\r\n        index = np.random.randint(0, 9999, 100)\r\n        digit = np.zeros((10*28,10*28), np.uint8)\r\n        k = 0\r\n        for x in range(0, 10):\r\n            for y in range(0, 10):\r\n                    digit[x*28:(x+1)*28, y*28:(y+1)*28] = X_test[index[k]]\r\n                    k = k + 1  \r\n        with col1:\r\n            st.latex(\"IMAGE\")\r\n            st.write()\r\n            st.write()\r\n            cv2.imwrite('pages/KNN1/digit.jpg', digit)\r\n            image = Image.open('pages/KNN1/digit.jpg')\r\n            st.image(image, caption='IMAGE')\r\n            sample = np.zeros((100,28,28), np.uint8)\r\n            for i in range(0, 100):\r\n                sample[i] = X_test[index[i]]\r\n                \r\n            RESHAPED = 784\r\n            sample = sample.reshape(100, RESHAPED) \r\n            predicted = knn.predict(sample)\r\n            k = 0\r\n            with col2:\r\n                st.latex(\"Ket qua nhan dang\")\r\n                for x in range(0, 10):\r\n                    ketqua = ''\r\n                    for y in range(0, 10):\r\n                        ketqua = ketqua + '%3d' % (predicted[k])\r\n                        k = k + 1\r\n                    st.write(ketqua )\r\nelse:\r\n    st.header(\"Bài 8\")
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pages/KNN.py b/pages/KNN.py
--- a/pages/KNN.py	
+++ b/pages/KNN.py	
@@ -27,7 +27,7 @@
         if val == key:
             return value
 
-app_mode = st.sidebar.selectbox('Select Page',['Bai01','Bai02', 'Bai03', 'Bai3a', 'Bai04', 'Bai08']) 
+app_mode = st.sidebar.selectbox('Select Page',['Bai01','Bai02', 'Bai03', 'Bai3a', 'Bai04', 'Bai05']) 
 
 if app_mode=='Bai01':
     
@@ -182,7 +182,6 @@
 
     st.image('pages/KNN1/digit.jpg')
 elif (app_mode == 'Bai04'):
-    
     from PIL import ImageTk, Image
     st.header("Bài 4")
     mnist = keras.datasets.mnist
@@ -223,4 +222,5 @@
                         k = k + 1
                     st.write(ketqua )
 else:
+    from PIL import ImageTk, Image
     st.header("Bài 8")
\ No newline at end of file
Index: pages/SVM.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import streamlit as st\r\nfrom sklearn.datasets import make_blobs\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import accuracy_score\r\n\r\nfrom sklearn.svm import LinearSVC\r\nfrom sklearn.svm import SVC\r\nfrom sklearn.inspection import DecisionBoundaryDisplay\r\n\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\nst.markdown(\"# SVM ❄️\")\r\nst.sidebar.markdown(\"# SVM ❄️\")\r\n\r\ndef get_fvalue(val):\r\n    feature_dict = {\"No\":1,\"Yes\":2}\r\n    for key,value in feature_dict.items():\r\n        if val == key:\r\n            return value\r\n\r\ndef get_value(val,my_dict):\r\n    for key,value in my_dict.items():\r\n        if val == key:\r\n            return value\r\n\r\napp_mode = st.sidebar.selectbox('Select Page',['Bai1','Bai1a','Bai2','plot_linearsvc_support_vectors']) \r\n\r\nif app_mode=='Bai1':\r\n    st.title(\"Bài 1\") \r\n\r\n    np.random.seed(100)\r\n    N = 150\r\n\r\n    centers = [[2, 2], [7, 7]]\r\n    n_classes = len(centers)\r\n    data, labels = make_blobs(n_samples=N, \r\n                            centers=np.array(centers),\r\n                            random_state=1)\r\n\r\n    nhom_0 = []\r\n    nhom_1 = []\r\n\r\n    for i in range(0, N):\r\n        if labels[i] == 0:\r\n            nhom_0.append([data[i,0], data[i,1]])\r\n        elif labels[i] == 1:\r\n            nhom_1.append([data[i,0], data[i,1]])\r\n\r\n    nhom_0 = np.array(nhom_0)\r\n    nhom_1 = np.array(nhom_1)\r\n\r\n    res = train_test_split(data, labels, \r\n                       train_size=0.8,\r\n                       test_size=0.2,\r\n                       random_state=1)\r\n    \r\n    train_data, test_data, train_labels, test_labels = res \r\n\r\n    nhom_0 = []\r\n    nhom_1 = []\r\n\r\n    SIZE = train_data.shape[0]\r\n    for i in range(0, SIZE):\r\n        if train_labels[i] == 0:\r\n            nhom_0.append([train_data[i,0], train_data[i,1]])\r\n        elif train_labels[i] == 1:\r\n            nhom_1.append([train_data[i,0], train_data[i,1]])\r\n\r\n    nhom_0 = np.array(nhom_0)\r\n    nhom_1 = np.array(nhom_1)\r\n\r\n    st.write('Nhóm 0: ', nhom_0)\r\n    st.write('Nhóm 1: ', nhom_1)\r\n\r\n    svc = LinearSVC(C = 100, loss=\"hinge\", random_state=42, max_iter = 100000)\r\n\r\n    svc.fit(train_data, train_labels)\r\n\r\n    he_so = svc.coef_\r\n    intercept = svc.intercept_\r\n\r\n    predicted = svc.predict(test_data)\r\n    sai_so = accuracy_score(test_labels, predicted)\r\n    st.write('Sai số:', sai_so)\r\n\r\n    my_test = np.array([[2.5, 4.0]])\r\n    ket_qua = svc.predict(my_test)\r\n\r\n    st.write('Kết quả nhận dạng là nhóm:', ket_qua[0])\r\n\r\n    plt.plot(nhom_0[:,0], nhom_0[:,1], 'og', markersize = 2)\r\n    plt.plot(nhom_1[:,0], nhom_1[:,1], 'or', markersize = 2)\r\n\r\n    w = he_so[0]\r\n    a = -w[0] / w[1]\r\n    xx = np.linspace(2, 7, 100)\r\n    yy = a * xx - intercept[0] / w[1]\r\n\r\n    plt.plot(xx, yy, 'b')\r\n\r\n\r\n    decision_function = svc.decision_function(train_data)\r\n    support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\r\n    support_vectors = train_data[support_vector_indices]\r\n    support_vectors_x = support_vectors[:,0]\r\n    support_vectors_y = support_vectors[:,1]\r\n\r\n    ax = plt.gca()\r\n\r\n    DecisionBoundaryDisplay.from_estimator(\r\n        svc,\r\n        train_data,\r\n        ax=ax,\r\n        grid_resolution=50,\r\n        plot_method=\"contour\",\r\n        colors=\"k\",\r\n        levels=[-1, 0, 1],\r\n        alpha=0.5,\r\n        linestyles=[\"--\", \"-\", \"--\"],\r\n    )\r\n    plt.scatter(\r\n        support_vectors[:, 0],\r\n        support_vectors[:, 1],\r\n        s=100,\r\n        linewidth=1,\r\n        facecolors=\"none\",\r\n        edgecolors=\"k\",\r\n    )\r\n\r\n    plt.legend(['Nhóm 0', 'Nhóm 1'])\r\n    st.set_option('deprecation.showPyplotGlobalUse', False)\r\n    st.pyplot(fig=None, clear_figure=True)     \r\n    \r\nelif app_mode == 'Bai1a':\r\n    st.title('Bài 1a')\r\n\r\n    np.random.seed(100)\r\n    N = 150\r\n\r\n    centers = [[2, 2], [7, 7]]\r\n    n_classes = len(centers)\r\n    data, labels = make_blobs(n_samples=N, \r\n                            centers=np.array(centers),\r\n                            random_state=1)\r\n\r\n    nhom_0 = []\r\n    nhom_1 = []\r\n\r\n    for i in range(0, N):\r\n        if labels[i] == 0:\r\n            nhom_0.append([data[i,0], data[i,1]])\r\n        elif labels[i] == 1:\r\n            nhom_1.append([data[i,0], data[i,1]])\r\n\r\n    nhom_0 = np.array(nhom_0)\r\n    nhom_1 = np.array(nhom_1)\r\n\r\n    res = train_test_split(data, labels, \r\n                       train_size=0.8,\r\n                       test_size=0.2,\r\n                       random_state=1)\r\n    \r\n    train_data, test_data, train_labels, test_labels = res \r\n\r\n    nhom_0 = []\r\n    nhom_1 = []\r\n\r\n    SIZE = train_data.shape[0]\r\n    for i in range(0, SIZE):\r\n        if train_labels[i] == 0:\r\n            nhom_0.append([train_data[i,0], train_data[i,1]])\r\n        elif train_labels[i] == 1:\r\n            nhom_1.append([train_data[i,0], train_data[i,1]])\r\n\r\n    nhom_0 = np.array(nhom_0)\r\n    nhom_1 = np.array(nhom_1)\r\n\r\n    st.write('Nhóm 0: ', nhom_0)\r\n    st.write('Nhóm 1: ', nhom_1)\r\n\r\n\r\n    svc = LinearSVC(C = 100, loss=\"hinge\", random_state=42, max_iter = 100000)\r\n\r\n    svc.fit(train_data, train_labels)\r\n\r\n    he_so = svc.coef_\r\n    intercept = svc.intercept_\r\n\r\n    predicted = svc.predict(test_data)\r\n    sai_so = accuracy_score(test_labels, predicted)\r\n    st.write('sai số:', sai_so)\r\n\r\n    my_test = np.array([[2.5, 4.0]])\r\n    ket_qua = svc.predict(my_test)\r\n\r\n    st.write('Kết quả nhận dạng là nhóm:', ket_qua[0])\r\n\r\n    plt.plot(nhom_0[:,0], nhom_0[:,1], 'og', markersize = 2)\r\n    plt.plot(nhom_1[:,0], nhom_1[:,1], 'or', markersize = 2)\r\n\r\n    w = he_so[0]\r\n    a = -w[0] / w[1]\r\n    xx = np.linspace(2, 7, 100)\r\n    yy = a * xx - intercept[0] / w[1]\r\n\r\n    plt.plot(xx, yy, 'b')\r\n\r\n    w = he_so[0]\r\n    a = w[0]\r\n    b = w[1]\r\n    c = intercept[0]\r\n    \r\n    distance = np.zeros(SIZE, np.float32)\r\n    for i in range(0, SIZE):\r\n        x0 = train_data[i,0]\r\n        y0 = train_data[i,1]\r\n        d = np.abs(a*x0 + b*y0 + c)/np.sqrt(a**2 + b**2)\r\n        distance[i] = d\r\n    st.write('Khoảng cách:')\r\n    st.write(distance)\r\n    vi_tri_min = np.argmin(distance)\r\n    min_val = np.min(distance)\r\n    st.write('vị trí min', vi_tri_min)\r\n    st.write('giá trị min', min_val)\r\n    st.write('Những giá trị gần min')\r\n    vi_tri = []\r\n    for i in range(0, SIZE):\r\n        if (distance[i] - min_val) <= 1.0E-3:\r\n            st.write(distance[i])\r\n            vi_tri.append(i)\r\n    st.write(vi_tri)\r\n    for i in vi_tri:\r\n        x = train_data[i,0]\r\n        y = train_data[i,1]\r\n        plt.plot(x, y, 'rs')\r\n\r\n    i = vi_tri[0]\r\n    x0 = train_data[i,0]\r\n    y0 = train_data[i,1]\r\n    c = -a*x0 -b*y0\r\n    xx = np.linspace(2, 7, 100)\r\n    yy = -a*xx/b - c/b\r\n    plt.plot(xx, yy, 'b--')\r\n\r\n    i = vi_tri[2]\r\n    x0 = train_data[i,0]\r\n    y0 = train_data[i,1]\r\n    c = -a*x0 -b*y0\r\n    xx = np.linspace(2, 7, 100)\r\n    yy = -a*xx/b - c/b\r\n    plt.plot(xx, yy, 'b--')\r\n\r\n\r\n    plt.legend(['Nhom 0', 'Nhom 1'])\r\n\r\n    st.set_option('deprecation.showPyplotGlobalUse', False)\r\n    st.pyplot(fig=None, clear_figure=True) \r\n    \r\nelif app_mode == 'Bai2':\r\n    st.title(\"Bài 2\") \r\n\r\n    np.random.seed(100)\r\n    N = 150\r\n\r\n    centers = [[2, 2], [7, 7]]\r\n    n_classes = len(centers)\r\n    data, labels = make_blobs(n_samples=N, \r\n                            centers=np.array(centers),\r\n                            random_state=1)\r\n\r\n    nhom_0 = []\r\n    nhom_1 = []\r\n\r\n    for i in range(0, N):\r\n        if labels[i] == 0:\r\n            nhom_0.append([data[i,0], data[i,1]])\r\n        elif labels[i] == 1:\r\n            nhom_1.append([data[i,0], data[i,1]])\r\n\r\n    nhom_0 = np.array(nhom_0)\r\n    nhom_1 = np.array(nhom_1)\r\n\r\n    res = train_test_split(data, labels, \r\n                       train_size=0.8,\r\n                       test_size=0.2,\r\n                       random_state=1)\r\n    \r\n    train_data, test_data, train_labels, test_labels = res \r\n\r\n    nhom_0 = []\r\n    nhom_1 = []\r\n\r\n    SIZE = train_data.shape[0]\r\n    for i in range(0, SIZE):\r\n        if train_labels[i] == 0:\r\n            nhom_0.append([train_data[i,0], train_data[i,1]])\r\n        elif train_labels[i] == 1:\r\n            nhom_1.append([train_data[i,0], train_data[i,1]])\r\n\r\n    nhom_0 = np.array(nhom_0)\r\n    nhom_1 = np.array(nhom_1)\r\n\r\n    st.write('Nhóm 0: ', nhom_0)\r\n    st.write('Nhóm 1: ', nhom_1)\r\n\r\n\r\n    svc = SVC(C = 100, kernel='linear', random_state=42)\r\n\r\n    svc.fit(train_data, train_labels)\r\n\r\n    he_so = svc.coef_\r\n    intercept = svc.intercept_\r\n\r\n    predicted = svc.predict(test_data)\r\n    sai_so = accuracy_score(test_labels, predicted)\r\n    st.write('sai số:', sai_so)\r\n\r\n    my_test = np.array([[2.5, 4.0]])\r\n    ket_qua = svc.predict(my_test)\r\n\r\n    st.write('Kết quả nhận dạng là nhóm:', ket_qua[0])\r\n\r\n    plt.plot(nhom_0[:,0], nhom_0[:,1], 'og', markersize = 2)\r\n    plt.plot(nhom_1[:,0], nhom_1[:,1], 'or', markersize = 2)\r\n\r\n    w = he_so[0]\r\n    a = -w[0] / w[1]\r\n    xx = np.linspace(2, 7, 100)\r\n    yy = a * xx - intercept[0] / w[1]\r\n    plt.plot(xx, yy, 'b')\r\n\r\n    support_vectors = svc.support_vectors_\r\n    st.write(support_vectors)\r\n\r\n    w = he_so[0]\r\n    a = w[0]\r\n    b = w[1]\r\n\r\n    i = 0\r\n    x0 = support_vectors[i,0]\r\n    y0 = support_vectors[i,1]\r\n    plt.plot(x0, y0, 'rs')\r\n    c = -a*x0 -b*y0\r\n    xx = np.linspace(2, 7, 100)\r\n    yy = -a*xx/b - c/b\r\n    plt.plot(xx, yy, 'b--')\r\n\r\n    i = 1\r\n    x0 = support_vectors[i,0]\r\n    y0 = support_vectors[i,1]\r\n    plt.plot(x0, y0, 'rs')\r\n    c = -a*x0 -b*y0\r\n    xx = np.linspace(2, 7, 100)\r\n    yy = -a*xx/b - c/b\r\n    plt.plot(xx, yy, 'b--')\r\n\r\n    plt.legend(['Nhom 0', 'Nhom 1'])\r\n\r\n    st.set_option('deprecation.showPyplotGlobalUse', False)\r\n    st.pyplot(fig=None, clear_figure=True) \r\n\r\nelif app_mode == 'plot_linearsvc_support_vectors':\r\n    st.title('Plot linear SVC support vectors')\r\n    X, y = make_blobs(n_samples=40, centers=2, random_state=0)\r\n\r\n    plt.figure(figsize=(10, 5))\r\n    # \"hinge\" is the standard SVM loss\r\n    clf = LinearSVC(C=100, loss=\"hinge\", random_state=42).fit(X, y)\r\n    # obtain the support vectors through the decision function\r\n    decision_function = clf.decision_function(X)\r\n    # we can also calculate the decision function manually\r\n    # decision_function = np.dot(X, clf.coef_[0]) + clf.intercept_[0]\r\n    # The support vectors are the samples that lie within the margin\r\n    # boundaries, whose size is conventionally constrained to 1\r\n    support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\r\n    support_vectors = X[support_vector_indices]\r\n\r\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\r\n    ax = plt.gca()\r\n    DecisionBoundaryDisplay.from_estimator(\r\n        clf,\r\n        X,\r\n        ax=ax,\r\n        grid_resolution=50,\r\n        plot_method=\"contour\",\r\n        colors=\"k\",\r\n        levels=[-1, 0, 1],\r\n        alpha=0.5,\r\n        linestyles=[\"--\", \"-\", \"--\"],\r\n    )\r\n    plt.scatter(\r\n        support_vectors[:, 0],\r\n        support_vectors[:, 1],\r\n        s=100,\r\n        linewidth=1,\r\n        facecolors=\"none\",\r\n        edgecolors=\"k\",\r\n    )\r\n    plt.title(\"C = 100\")\r\n\r\n    fig = plt.tight_layout()\r\n\r\n    st.pyplot(fig) 
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pages/SVM.py b/pages/SVM.py
--- a/pages/SVM.py	
+++ b/pages/SVM.py	
@@ -301,8 +301,7 @@
     nhom_0 = np.array(nhom_0)
     nhom_1 = np.array(nhom_1)
 
-    st.write('Nhóm 0: ', nhom_0)
-    st.write('Nhóm 1: ', nhom_1)
+    st.write('Nhóm 0: ', nhom_0, 'Nhóm 1', nhom_1)
 
 
     svc = SVC(C = 100, kernel='linear', random_state=42)
@@ -331,7 +330,7 @@
     plt.plot(xx, yy, 'b')
 
     support_vectors = svc.support_vectors_
-    st.write(support_vectors)
+    st.write('support vector: ', support_vectors)
 
     w = he_so[0]
     a = w[0]
